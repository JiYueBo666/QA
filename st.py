import streamlit as st
import requests
import time
from openai import OpenAI

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="é—®ç­”ç³»ç»Ÿ", layout="centered")
st.title("æ··åˆæ£€ç´¢é—®ç­”ç³»ç»Ÿ")

# å®šä¹‰ API åœ°å€ï¼ˆæ ¹æ®ä½ çš„ FastAPI æœåŠ¡åœ°å€ä¿®æ”¹ï¼‰
API_URL = "http://localhost:8000/api/qa"


def generate_response(query, results):

    titles = []
    questions = []
    answers = []
    scores = []

    client = OpenAI(
        api_key="sk-T4T1ktwoe50DKBY6C79c3f0903Bb4dC798F5E7069aF966B7",
        base_url="https://api.openai-next.com/v1",
    )

    for idx, ans in enumerate(results, start=1):
        titles.append(ans["title"])
        questions.append(ans["ask"])
        answers.append(ans["answer"])
        scores.append(ans["final_score"])

    prompt_title = "ä¸‹é¢æ˜¯ä¸€äº›æœç´¢å‡ºæ¥çš„å…¶ä»–ç—…äººçš„æé—®å’Œå›å¤ç»“æœ"

    formatted_results = ""
    for i in range(len(titles)):
        formatted_results += f"""ç¤ºä¾‹ {i+1}:
    æ ‡é¢˜: {titles[i]}
    é—®é¢˜: {questions[i]}
    ç­”æ¡ˆ: {answers[i]}
    #
    """

    print(formatted_results)

    user_prompt = """
    ä¸‹é¢æ˜¯ç”¨æˆ·çš„é—®é¢˜:{query}
    è¯·ä½ å¼€å§‹å›ç­”ã€‚

"""

    final_prompt = prompt_title + formatted_results + user_prompt.format(query=query)

    sys_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—é—®ç­”åŠ©æ‰‹ï¼Œ"
        "è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæ£€ç´¢ç»“æœæä¾›å‡†ç¡®çš„ç­”æ¡ˆï¼Œç»™äºˆç”¨æˆ·å»ºè®®"
    )

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        stream=True,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": final_prompt},
        ],
    )

    return completion


# åˆ›å»ºè¾“å…¥æ¡†
user_query = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
if user_query:
    try:
        start = time.time()

        with st.status("æ­£åœ¨æ£€ç´¢é—®é¢˜...", expanded=True) as status:
            results = requests.post(API_URL, json={"query": user_query})
            end = time.time()
            status.update(
                label=f"æ£€ç´¢å®Œæˆï¼Œç”¨æ—¶:{end - start:.2f}s",
                state="complete",
                expanded=True,
            )

        if results.status_code == 200:
            results = results.json()

            # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç”¨äºæ˜¾ç¤ºâ€œç”Ÿæˆä¸­â€å’Œâ€œç”Ÿæˆå®Œæˆâ€çš„æç¤º
            spinner_placeholder = st.empty()
            spinner_placeholder.info("ğŸ§  æ­£åœ¨ç”Ÿæˆå›å¤...")

            # è·å–æµå¼å“åº”
            response_stream = generate_response(user_query, results)

            # å®šä¹‰ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ä¾› st.write_stream ä½¿ç”¨
            def stream_output():
                first_token_received = False
                for chunk in response_stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        if not first_token_received:
                            first_token_received = True
                            spinner_placeholder.success("âœ… ç”Ÿæˆå®Œæˆ")
                        yield content

            # ä½¿ç”¨ write_stream æ˜¾ç¤ºæµå¼è¾“å‡º
            st.write_stream(stream_output())

        else:
            st.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {results.status_code}")
    except Exception as e:
        st.error(f"è¿æ¥é”™è¯¯: {e}")
